{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Обзор-данных\" data-toc-modified-id=\"Обзор-данных-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Обзор данных</a></span></li><li><span><a href=\"#Подготовка-данных\" data-toc-modified-id=\"Подготовка-данных-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Подготовка данных</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Тестирование\" data-toc-modified-id=\"Тестирование-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Тестирование</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**В данной работе мы будем искать и обучать модель способную разделять комментарии пользователей на позитивные и негативные** <br>\n",
    "Модель будет использоваться в интернет-магазине \"Викишоп\", в сервисе, где пользователи могут самостоятельно дополнять и редактировать описание товаров. Модель будет нужна для определения токсичных комментариев и отправки их на модерацию. <br>\n",
    "Для данной работы мы имеем набор данных с разметкой об их токсичности. Сначала рассмотрим имеющийся датасет и подумаем какая часть данных может нам пригодится. Далее проведем очистку текстовых данных от лишних символов, цифр и пунктуации, разберем комментарии на отдельные токены и проведем лемматизацию текстов. Переведем данные в векторный тип методом TF-IDF. Затем обучим несколько моделей и выберем лучшую. В конце проведем проверку моделй на тестовых данных.<br>\n",
    "Необходимая мметрика качества работы моделей в данной работе _F1_.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обзор данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установим и импортируем необходимые компоненты и библиотеки для работы, загрузим имеющиеся данные и посмотрим на них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "\n",
    "stopwords = English.Defaults.stop_words\n",
    "\n",
    "# from pandas_profiling import ProfileReport\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "\n",
    "rcParams[\"figure.figsize\"] = 15, 8\n",
    "\n",
    "from sklearn.utils import resample, shuffle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "SEED = 777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv(\n",
    "        \"..\\\\Desktop\\\\Jupiter_and_projects\\\\data_sets\\\\toxic_comments.csv\"\n",
    "    )\n",
    "except:\n",
    "    data = pd.read_csv(\"https://code.s3.yandex.net/datasets/toxic_comments.csv\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "ProfileReport(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Как видно из отчета, мы имеем большой датасет на 159 тыс. записей, при этом у него только 3 столбца - текст комментария, метка токсичности и столбец с номером записи по порядку.<br>\n",
    "Дубликаты в данных отсутсвуют.<br>\n",
    "Если посмотреть на целевой столбец `toxic` то он имеет распределение бинарного значения о наличии токсичности комментария. При этом в наших данных распределение токсичных и нейтральных комментариев неравномерно, токсичные комментарии составляют около 11% от наших данных.<br>\n",
    "Сами тексты комментариев представлены на английском языке, содержат знаки препинания, верхний и нижний регистр, цифры и различные абревиатуры. Также комментарии имеют различную длину и количество слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала посмотрим какие длины текстовых данных мы имеем и как они распределяются в нашем датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = pd.Series([len(line) for line in data[\"text\"]]).hist(\n",
    "    color=\"DarkGreen\", bins=90, rwidth=0.9\n",
    ")\n",
    "ax.set_title(\"Распределение длины текста в данных\")\n",
    "ax.set_xlabel(\"Количество символов в текстах\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что большинство текстов имееют количество символов меньше 2000, но так же имеются отдельные выбросы с длиной текста до 5000 символов. При наличии большого количества символов мы сильно нагружаем модель и большая размерность вектора может сбивать модель - ограничим нашу выборку текстами, имеющими длину до 2500 символов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156471, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes = []\n",
    "i = 0\n",
    "for line in data[\"text\"]:\n",
    "    if len(line) > 2500:\n",
    "        indexes.append(i)\n",
    "    i += 1\n",
    "data = data.drop(index=indexes)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для коррекного перевода текстов вектора надо обработать сам текст. <br>\n",
    "Напишем функцию, которая будет делать следующее:\n",
    "- Оставлять в наших текстах только английские буквенные символы, без цифр и знаков пунктуации;\n",
    "- Приводить все символы к нижнему регистру;\n",
    "- Удалять все лишние пробелы;\n",
    "- Преобразовывать слова в токены и возвращать их леммы.<br>\n",
    "\n",
    "На выходе мы должны получить массив текстов, готовый к переводу в векторный вид. Для лемматизации слов в текстах воспользуемся моделью из библиотеки spaСy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "lemmatizer = nlp.get_pipe(\"lemmatizer\")\n",
    "\n",
    "\n",
    "def clean_text(array_of_text):\n",
    "    lemma_full = []\n",
    "\n",
    "    low_text = [re.sub(r\"[^a-z]+\", \" \", line.lower()) for line in array_of_text]\n",
    "\n",
    "    doc_for_lemma = list(nlp.pipe(low_text))\n",
    "\n",
    "    for i in range(len(low_text)):\n",
    "        lemma_full.append([])\n",
    "        lemma_full[i] = \" \".join([token.lemma_ for token in doc_for_lemma[i]])\n",
    "\n",
    "    return np.array(lemma_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее чтобы не нагружать процессы обработки текста сразу выделим данные для обучающей выборки и для тестовой.<br>\n",
    "Для обучающей части данных составим выборку самостоятельно. Так как в данных присутствует сильный дисбалланс целевого признака, ограничим данные которые пойдут на обучение моделей, таким образом мы дополнительно снизим нагрузку на ядро. Чтобы модель могла справедливо выучить и плохие примеры и хорошие соберем обучающую выборку пополам из 2х классов целевой переменной. Возьмем по 14_000 примеров текстов из каждого класса. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_positive = resample(\n",
    "    data.loc[data[\"toxic\"] == 0], n_samples=14000, random_state=SEED\n",
    ")\n",
    "comments_negative = resample(\n",
    "    data.loc[data[\"toxic\"] == 1], n_samples=14000, random_state=SEED\n",
    ")\n",
    "comments = pd.concat([comments_positive] + [comments_negative])\n",
    "comments = shuffle(comments, random_state=SEED)\n",
    "comments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее соберем выборку данных для тестирования моделей. Чтобы тестирование было максимально справедливым, оставим пропорции данных из разных классов так же, как они были в исходном датасете - 11% класса `1` и 89% класса `0`.<br>\n",
    "Выборку будем собирать из данных, которые не вошли в обучающую выборку. <br>\n",
    "Для тестирования возьмем 10_000 примеров текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lost = data.drop(index=comments.index)\n",
    "\n",
    "com_positive = resample(\n",
    "    data_lost.loc[data_lost[\"toxic\"] == 0], n_samples=8900, random_state=SEED\n",
    ")\n",
    "com_negative = resample(\n",
    "    data_lost.loc[data_lost[\"toxic\"] == 1], n_samples=1100, random_state=SEED\n",
    ")\n",
    "comments_test = pd.concat([com_positive] + [com_negative])\n",
    "comments_test = shuffle(comments_test, random_state=SEED)\n",
    "comments_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь из обучающей и тестовой выборки выделим признаки для обучения и целевой признак в разные переменные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train = comments[\"text\"]\n",
    "fea_test = comments_test[\"text\"]\n",
    "\n",
    "target_train = comments[\"toxic\"]\n",
    "target_test = comments_test[\"toxic\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь применим функцию преобразования текста к признакам для обучения и тестирования моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример преобразованного текста для обучения: \n",
      " head tag in msw reference hi just wonder why you remove the head tag in the msw reference in chlorocebus regard\n",
      "Пример преобразованного текста для тестирования: \n",
      "   I be think of convert today s pound sterling to today s canadian dollar you didn t have canadian dollar before from however there be canadian pound but nova scotia didn t use canadian currency until confederation the idea of convert the pound sterling from the th century to today give a sense of the purchasing power so the conversion of today s pound to today s dollar would give a well idea of purchase power for canada to sum up I m think of th century present day present day cad maxim talk\n",
      "CPU times: total: 2min 53s\n",
      "Wall time: 2min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "fea_train = clean_text(fea_train)\n",
    "print(\"Пример преобразованного текста для обучения:\", \"\\n\", fea_train[1])\n",
    "\n",
    "fea_test = clean_text(fea_test)\n",
    "print(\"Пример преобразованного текста для тестирования:\", \"\\n\", fea_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные преобразованы и готовы для работы с моделями машинного обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь подготовим словари с моделями, параметрами для подбора через GridSearchCV, оценками и обученными моделями. В Пайплайн процесса добавим Векторизатор TfidfVectorizer из библиотеки sklearn для преобразования тексовых данных в вектора по методу TF-IDF.<br>\n",
    "Для сравнения результатов будем использовать следующие модели:\n",
    "- LogisticRegression\n",
    "- CatBoostClassifier\n",
    "- LGBMClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_LogReg = LogisticRegression(random_state=SEED, max_iter=9000)\n",
    "\n",
    "clf_Cat = CatBoostClassifier(\n",
    "    silent=True, learning_rate=0.28, random_state=SEED, min_data_in_leaf=20\n",
    ")\n",
    "\n",
    "clf_LGBM = LGBMClassifier(learning_rate=0.18, random_state=SEED)\n",
    "\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"vector\",\n",
    "            TfidfVectorizer(\n",
    "                norm=None, max_df=0.8, max_features=6500, decode_error=\"replace\"\n",
    "            ),\n",
    "        ),\n",
    "        (\"clf\", clf_LogReg),\n",
    "    ]\n",
    ")\n",
    "\n",
    "params_LogReg = {\"clf__solver\": [\"sag\", \"saga\"], \"clf\": [clf_LogReg]}\n",
    "\n",
    "params_Cat = {\"clf__iterations\": [200, 2200], \"clf__depth\": [3, 5], \"clf\": [clf_Cat]}\n",
    "\n",
    "params_LGBM = {\n",
    "    \"clf__n_estimators\": [300, 2500],\n",
    "    \"clf__min_data_in_leaf\": [20, 50],\n",
    "    \"clf__max_depth\": [3, 4, 7],\n",
    "    \"clf\": [clf_LGBM],\n",
    "}\n",
    "params = [params_LogReg, params_Cat, params_LGBM]\n",
    "\n",
    "cv = KFold(n_splits=4, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запускаем подбор оптимальной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 18 candidates, totalling 72 fits\n",
      "[CV 1/4; 1/18] START clf=LogisticRegression(max_iter=9000, random_state=777), clf__solver=sag\n",
      "[CV 1/4; 1/18] END clf=LogisticRegression(max_iter=9000, random_state=777), clf__solver=sag;, score=0.900 total time=  31.7s\n",
      "[CV 2/4; 1/18] START clf=LogisticRegression(max_iter=9000, random_state=777), clf__solver=sag\n",
      "[CV 2/4; 1/18] END clf=LogisticRegression(max_iter=9000, random_state=777), clf__solver=sag;, score=0.903 total time=  32.2s\n",
      "[CV 3/4; 1/18] START clf=LogisticRegression(max_iter=9000, random_state=777), clf__solver=sag\n",
      "[CV 3/4; 1/18] END clf=LogisticRegression(max_iter=9000, random_state=777), clf__solver=sag;, score=0.908 total time=  31.5s\n",
      "[CV 4/4; 1/18] START clf=LogisticRegression(max_iter=9000, random_state=777), clf__solver=sag\n",
      "[CV 4/4; 1/18] END clf=LogisticRegression(max_iter=9000, random_state=777), clf__solver=sag;, score=0.901 total time=  31.6s\n",
      "[CV 1/4; 2/18] START clf=LogisticRegression(max_iter=9000, random_state=777), clf__solver=saga\n",
      "[CV 1/4; 2/18] END clf=LogisticRegression(max_iter=9000, random_state=777), clf__solver=saga;, score=0.894 total time=  37.3s\n",
      "[CV 2/4; 2/18] START clf=LogisticRegression(max_iter=9000, random_state=777), clf__solver=saga\n",
      "[CV 2/4; 2/18] END clf=LogisticRegression(max_iter=9000, random_state=777), clf__solver=saga;, score=0.895 total time=  38.6s\n",
      "[CV 3/4; 2/18] START clf=LogisticRegression(max_iter=9000, random_state=777), clf__solver=saga\n",
      "[CV 3/4; 2/18] END clf=LogisticRegression(max_iter=9000, random_state=777), clf__solver=saga;, score=0.900 total time=  38.2s\n",
      "[CV 4/4; 2/18] START clf=LogisticRegression(max_iter=9000, random_state=777), clf__solver=saga\n",
      "[CV 4/4; 2/18] END clf=LogisticRegression(max_iter=9000, random_state=777), clf__solver=saga;, score=0.891 total time=  37.6s\n",
      "[CV 1/4; 3/18] START clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=3, clf__iterations=200\n",
      "[CV 1/4; 3/18] END clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=3, clf__iterations=200;, score=0.890 total time=   4.0s\n",
      "[CV 2/4; 3/18] START clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=3, clf__iterations=200\n",
      "[CV 2/4; 3/18] END clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=3, clf__iterations=200;, score=0.906 total time=   3.9s\n",
      "[CV 3/4; 3/18] START clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=3, clf__iterations=200\n",
      "[CV 3/4; 3/18] END clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=3, clf__iterations=200;, score=0.894 total time=   3.9s\n",
      "[CV 4/4; 3/18] START clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=3, clf__iterations=200\n",
      "[CV 4/4; 3/18] END clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=3, clf__iterations=200;, score=0.890 total time=   3.9s\n",
      "[CV 1/4; 4/18] START clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=3, clf__iterations=2200\n",
      "[CV 1/4; 4/18] END clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=3, clf__iterations=2200;, score=0.928 total time=  30.4s\n",
      "[CV 2/4; 4/18] START clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=3, clf__iterations=2200\n",
      "[CV 2/4; 4/18] END clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=3, clf__iterations=2200;, score=0.940 total time=  30.9s\n",
      "[CV 3/4; 4/18] START clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=3, clf__iterations=2200\n",
      "[CV 3/4; 4/18] END clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=3, clf__iterations=2200;, score=0.933 total time=  31.8s\n",
      "[CV 4/4; 4/18] START clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=3, clf__iterations=2200\n",
      "[CV 4/4; 4/18] END clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=3, clf__iterations=2200;, score=0.931 total time=  30.6s\n",
      "[CV 1/4; 5/18] START clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=5, clf__iterations=200\n",
      "[CV 1/4; 5/18] END clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=5, clf__iterations=200;, score=0.899 total time=   5.4s\n",
      "[CV 2/4; 5/18] START clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=5, clf__iterations=200\n",
      "[CV 2/4; 5/18] END clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=5, clf__iterations=200;, score=0.915 total time=   5.2s\n",
      "[CV 3/4; 5/18] START clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=5, clf__iterations=200\n",
      "[CV 3/4; 5/18] END clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=5, clf__iterations=200;, score=0.909 total time=   5.2s\n",
      "[CV 4/4; 5/18] START clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=5, clf__iterations=200\n",
      "[CV 4/4; 5/18] END clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=5, clf__iterations=200;, score=0.905 total time=   5.2s\n",
      "[CV 1/4; 6/18] START clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=5, clf__iterations=2200\n",
      "[CV 1/4; 6/18] END clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=5, clf__iterations=2200;, score=0.933 total time=  44.6s\n",
      "[CV 2/4; 6/18] START clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=5, clf__iterations=2200\n",
      "[CV 2/4; 6/18] END clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=5, clf__iterations=2200;, score=0.943 total time=  44.7s\n",
      "[CV 3/4; 6/18] START clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=5, clf__iterations=2200\n",
      "[CV 3/4; 6/18] END clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=5, clf__iterations=2200;, score=0.938 total time=  44.7s\n",
      "[CV 4/4; 6/18] START clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=5, clf__iterations=2200\n",
      "[CV 4/4; 6/18] END clf=<catboost.core.CatBoostClassifier object at 0x000002CFC2626460>, clf__depth=5, clf__iterations=2200;, score=0.934 total time=  45.4s\n",
      "[CV 1/4; 7/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=20, clf__n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[CV 1/4; 7/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=20, clf__n_estimators=300;, score=0.886 total time=   1.4s\n",
      "[CV 2/4; 7/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=20, clf__n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[CV 2/4; 7/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=20, clf__n_estimators=300;, score=0.898 total time=   1.4s\n",
      "[CV 3/4; 7/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=20, clf__n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[CV 3/4; 7/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=20, clf__n_estimators=300;, score=0.894 total time=   1.5s\n",
      "[CV 4/4; 7/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=20, clf__n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[CV 4/4; 7/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=20, clf__n_estimators=300;, score=0.889 total time=   1.4s\n",
      "[CV 1/4; 8/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=20, clf__n_estimators=2500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[CV 1/4; 8/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=20, clf__n_estimators=2500;, score=0.925 total time=   2.7s\n",
      "[CV 2/4; 8/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=20, clf__n_estimators=2500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[CV 2/4; 8/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=20, clf__n_estimators=2500;, score=0.934 total time=   2.8s\n",
      "[CV 3/4; 8/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=20, clf__n_estimators=2500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[CV 3/4; 8/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=20, clf__n_estimators=2500;, score=0.938 total time=   2.8s\n",
      "[CV 4/4; 8/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=20, clf__n_estimators=2500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[CV 4/4; 8/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=20, clf__n_estimators=2500;, score=0.930 total time=   2.7s\n",
      "[CV 1/4; 9/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=50, clf__n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[CV 1/4; 9/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=50, clf__n_estimators=300;, score=0.883 total time=   1.3s\n",
      "[CV 2/4; 9/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=50, clf__n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[CV 2/4; 9/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=50, clf__n_estimators=300;, score=0.891 total time=   1.3s\n",
      "[CV 3/4; 9/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=50, clf__n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[CV 3/4; 9/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=50, clf__n_estimators=300;, score=0.887 total time=   1.3s\n",
      "[CV 4/4; 9/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=50, clf__n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[CV 4/4; 9/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=50, clf__n_estimators=300;, score=0.881 total time=   1.3s\n",
      "[CV 1/4; 10/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=50, clf__n_estimators=2500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[CV 1/4; 10/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=50, clf__n_estimators=2500;, score=0.918 total time=   2.4s\n",
      "[CV 2/4; 10/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=50, clf__n_estimators=2500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[CV 2/4; 10/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=50, clf__n_estimators=2500;, score=0.919 total time=   2.4s\n",
      "[CV 3/4; 10/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=50, clf__n_estimators=2500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[CV 3/4; 10/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=50, clf__n_estimators=2500;, score=0.924 total time=   2.4s\n",
      "[CV 4/4; 10/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=50, clf__n_estimators=2500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[CV 4/4; 10/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=3, clf__min_data_in_leaf=50, clf__n_estimators=2500;, score=0.920 total time=   2.4s\n",
      "[CV 1/4; 11/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=20, clf__n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[CV 1/4; 11/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=20, clf__n_estimators=300;, score=0.896 total time=   1.4s\n",
      "[CV 2/4; 11/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=20, clf__n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[CV 2/4; 11/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=20, clf__n_estimators=300;, score=0.910 total time=   1.4s\n",
      "[CV 3/4; 11/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=20, clf__n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[CV 3/4; 11/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=20, clf__n_estimators=300;, score=0.906 total time=   1.4s\n",
      "[CV 4/4; 11/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=20, clf__n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[CV 4/4; 11/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=20, clf__n_estimators=300;, score=0.899 total time=   1.4s\n",
      "[CV 1/4; 12/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=20, clf__n_estimators=2500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[CV 1/4; 12/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=20, clf__n_estimators=2500;, score=0.929 total time=   3.0s\n",
      "[CV 2/4; 12/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=20, clf__n_estimators=2500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[CV 2/4; 12/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=20, clf__n_estimators=2500;, score=0.937 total time=   3.0s\n",
      "[CV 3/4; 12/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=20, clf__n_estimators=2500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[CV 3/4; 12/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=20, clf__n_estimators=2500;, score=0.937 total time=   3.0s\n",
      "[CV 4/4; 12/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=20, clf__n_estimators=2500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[CV 4/4; 12/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=20, clf__n_estimators=2500;, score=0.933 total time=   3.0s\n",
      "[CV 1/4; 13/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=50, clf__n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[CV 1/4; 13/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=50, clf__n_estimators=300;, score=0.889 total time=   1.3s\n",
      "[CV 2/4; 13/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=50, clf__n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[CV 2/4; 13/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=50, clf__n_estimators=300;, score=0.900 total time=   1.3s\n",
      "[CV 3/4; 13/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=50, clf__n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[CV 3/4; 13/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=50, clf__n_estimators=300;, score=0.897 total time=   1.3s\n",
      "[CV 4/4; 13/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=50, clf__n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[CV 4/4; 13/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=50, clf__n_estimators=300;, score=0.890 total time=   1.3s\n",
      "[CV 1/4; 14/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=50, clf__n_estimators=2500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[CV 1/4; 14/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=50, clf__n_estimators=2500;, score=0.916 total time=   2.6s\n",
      "[CV 2/4; 14/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=50, clf__n_estimators=2500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[CV 2/4; 14/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=50, clf__n_estimators=2500;, score=0.924 total time=   2.7s\n",
      "[CV 3/4; 14/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=50, clf__n_estimators=2500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[CV 3/4; 14/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=50, clf__n_estimators=2500;, score=0.927 total time=   2.7s\n",
      "[CV 4/4; 14/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=50, clf__n_estimators=2500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[CV 4/4; 14/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=4, clf__min_data_in_leaf=50, clf__n_estimators=2500;, score=0.922 total time=   2.6s\n",
      "[CV 1/4; 15/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=20, clf__n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[CV 1/4; 15/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=20, clf__n_estimators=300;, score=0.912 total time=   1.6s\n",
      "[CV 2/4; 15/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=20, clf__n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[CV 2/4; 15/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=20, clf__n_estimators=300;, score=0.923 total time=   1.6s\n",
      "[CV 3/4; 15/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=20, clf__n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[CV 3/4; 15/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=20, clf__n_estimators=300;, score=0.921 total time=   1.6s\n",
      "[CV 4/4; 15/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=20, clf__n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[CV 4/4; 15/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=20, clf__n_estimators=300;, score=0.918 total time=   1.6s\n",
      "[CV 1/4; 16/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=20, clf__n_estimators=2500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[CV 1/4; 16/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=20, clf__n_estimators=2500;, score=0.928 total time=   4.4s\n",
      "[CV 2/4; 16/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=20, clf__n_estimators=2500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[CV 2/4; 16/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=20, clf__n_estimators=2500;, score=0.935 total time=   4.4s\n",
      "[CV 3/4; 16/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=20, clf__n_estimators=2500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[CV 3/4; 16/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=20, clf__n_estimators=2500;, score=0.933 total time=   4.5s\n",
      "[CV 4/4; 16/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=20, clf__n_estimators=2500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[CV 4/4; 16/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=20, clf__n_estimators=2500;, score=0.931 total time=   4.4s\n",
      "[CV 1/4; 17/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=50, clf__n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[CV 1/4; 17/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=50, clf__n_estimators=300;, score=0.903 total time=   1.4s\n",
      "[CV 2/4; 17/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=50, clf__n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[CV 2/4; 17/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=50, clf__n_estimators=300;, score=0.913 total time=   1.4s\n",
      "[CV 3/4; 17/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=50, clf__n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[CV 3/4; 17/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=50, clf__n_estimators=300;, score=0.915 total time=   1.4s\n",
      "[CV 4/4; 17/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=50, clf__n_estimators=300\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[CV 4/4; 17/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=50, clf__n_estimators=300;, score=0.909 total time=   1.4s\n",
      "[CV 1/4; 18/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=50, clf__n_estimators=2500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[CV 1/4; 18/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=50, clf__n_estimators=2500;, score=0.916 total time=   3.7s\n",
      "[CV 2/4; 18/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=50, clf__n_estimators=2500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[CV 2/4; 18/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=50, clf__n_estimators=2500;, score=0.924 total time=   3.7s\n",
      "[CV 3/4; 18/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=50, clf__n_estimators=2500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[CV 3/4; 18/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=50, clf__n_estimators=2500;, score=0.924 total time=   3.6s\n",
      "[CV 4/4; 18/18] START clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=50, clf__n_estimators=2500\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[CV 4/4; 18/18] END clf=LGBMClassifier(learning_rate=0.18, random_state=777), clf__max_depth=7, clf__min_data_in_leaf=50, clf__n_estimators=2500;, score=0.920 total time=   3.7s\n",
      "CPU times: total: 37min 53s\n",
      "Wall time: 13min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'clf': <catboost.core.CatBoostClassifier at 0x2cfc2626460>,\n",
       "  'clf__depth': 5,\n",
       "  'clf__iterations': 2200},\n",
       " 0.9369820149843014,\n",
       " Pipeline(steps=[('vector',\n",
       "                  TfidfVectorizer(decode_error='replace', max_df=0.8,\n",
       "                                  max_features=6500, norm=None)),\n",
       "                 ('clf',\n",
       "                  <catboost.core.CatBoostClassifier object at 0x000002CFB11B9040>)]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    pipe, param_grid=params, cv=cv, scoring=\"f1\", verbose=800, refit=True\n",
    ")\n",
    "\n",
    "grid.fit(fea_train, target_train)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "grid.best_params_, grid.best_score_, grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка лучшей модели на обучающихся данных: 0.937\n",
      "Лучшая модель:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<catboost.core.CatBoostClassifier at 0x2cfb11b9040>,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Оценка лучшей модели на обучающихся данных: {grid.best_score_:.3f}\")\n",
    "print(\"Лучшая модель:\")\n",
    "(best_model[\"clf\"],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем видеть, что все модели получили неплохие оценки на сбалансированной обучающей выборке, при этом лучший результат показывает модель CatBoostClassifier с оценкой `f1` = 0.937. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь протестируем модель, которая показала лучшие результаты на валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Оценка модели CatBoostClassifier тестовой выборке (f1): 0.762'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = best_model.predict(fea_test)\n",
    "test_score = f1_score(target_test, prediction)\n",
    "f\"Оценка модели CatBoostClassifier тестовой выборке (f1): {test_score:.3f}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучше всех результат показывает модель CatBoostClassifier, как и на обучении она имеет самую высокую метрику `f1` = 0.762 . При этом можно заметить, что у всех моделей оценки значительно снизились по сравнению с обучающей выборкой, что указывает на значимость классового распределения в имеющихся данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**В ходе работы мы получили обученную модель, способную разделять комментарии пользователей на позитивные и негативные** <br>\n",
    "\n",
    "В данной работе мы внимательно рассмотрели имеющиеся данные, нашли в них недочеты и почистили. Провели большую работу над тексами имеющихся комментариев - привели их к стандартному виду, откинув все лишнее. Далее, сбалансировали классы имеющихся данных для обучения моделей машинного обучения. Перевели данные в векторный вид по методу TF-IDF и обучили модели. Затем составили специальную справедливую тестовую выборку и на ней протестировали наши модели.<br>\n",
    "**В итоге мы получили обученную модель CatBoostClassifier с парметрами метрики качества _F1_ > 0.75**\n"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 400,
    "start_time": "2023-01-17T08:46:51.891Z"
   },
   {
    "duration": 100,
    "start_time": "2023-01-17T08:47:21.978Z"
   },
   {
    "duration": 2787,
    "start_time": "2023-01-17T08:47:54.002Z"
   },
   {
    "duration": 861,
    "start_time": "2023-01-17T08:48:07.851Z"
   },
   {
    "duration": 852,
    "start_time": "2023-01-17T08:59:39.749Z"
   },
   {
    "duration": 14010,
    "start_time": "2023-01-17T10:44:55.497Z"
   },
   {
    "duration": 2122,
    "start_time": "2023-01-17T10:45:31.223Z"
   },
   {
    "duration": 37933,
    "start_time": "2023-01-17T10:45:57.520Z"
   },
   {
    "duration": 9,
    "start_time": "2023-01-17T11:00:10.447Z"
   },
   {
    "duration": 155,
    "start_time": "2023-01-17T11:01:12.516Z"
   },
   {
    "duration": 136,
    "start_time": "2023-01-17T11:01:41.837Z"
   },
   {
    "duration": 155,
    "start_time": "2023-01-17T11:01:42.220Z"
   },
   {
    "duration": 13,
    "start_time": "2023-01-17T11:01:53.701Z"
   },
   {
    "duration": 162,
    "start_time": "2023-01-17T11:01:54.508Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-17T11:02:08.933Z"
   },
   {
    "duration": 17,
    "start_time": "2023-01-17T11:35:17.554Z"
   },
   {
    "duration": 13,
    "start_time": "2023-01-17T11:35:37.723Z"
   },
   {
    "duration": 12,
    "start_time": "2023-01-17T11:35:55.610Z"
   },
   {
    "duration": 1191,
    "start_time": "2023-01-17T11:36:00.851Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-17T11:46:00.094Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-17T11:46:46.087Z"
   },
   {
    "duration": 6,
    "start_time": "2023-01-17T11:46:49.119Z"
   },
   {
    "duration": 165,
    "start_time": "2023-01-17T11:46:56.175Z"
   },
   {
    "duration": 17,
    "start_time": "2023-01-17T11:47:17.888Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-17T11:47:52.183Z"
   },
   {
    "duration": 161,
    "start_time": "2023-01-17T11:47:55.975Z"
   },
   {
    "duration": 6,
    "start_time": "2023-01-17T11:48:05.528Z"
   },
   {
    "duration": 12,
    "start_time": "2023-01-17T11:48:19.655Z"
   },
   {
    "duration": 18,
    "start_time": "2023-01-17T11:50:13.577Z"
   },
   {
    "duration": 19,
    "start_time": "2023-01-17T11:51:20.009Z"
   },
   {
    "duration": 19,
    "start_time": "2023-01-17T11:51:30.913Z"
   },
   {
    "duration": 16,
    "start_time": "2023-01-17T11:51:51.769Z"
   },
   {
    "duration": 22,
    "start_time": "2023-01-17T11:52:03.530Z"
   },
   {
    "duration": 13,
    "start_time": "2023-01-17T11:52:12.300Z"
   },
   {
    "duration": 19,
    "start_time": "2023-01-17T11:52:25.411Z"
   },
   {
    "duration": 171,
    "start_time": "2023-01-17T11:52:31.498Z"
   },
   {
    "duration": 6,
    "start_time": "2023-01-17T12:03:48.317Z"
   },
   {
    "duration": 24,
    "start_time": "2023-01-17T12:04:47.230Z"
   },
   {
    "duration": 171,
    "start_time": "2023-01-17T12:04:48.771Z"
   },
   {
    "duration": 173,
    "start_time": "2023-01-17T12:05:00.967Z"
   },
   {
    "duration": 26,
    "start_time": "2023-01-17T12:05:23.917Z"
   },
   {
    "duration": 186,
    "start_time": "2023-01-17T12:05:26.917Z"
   },
   {
    "duration": 170,
    "start_time": "2023-01-17T12:07:11.598Z"
   },
   {
    "duration": 13874,
    "start_time": "2023-01-18T06:42:37.560Z"
   },
   {
    "duration": 5332,
    "start_time": "2023-01-18T06:42:51.436Z"
   },
   {
    "duration": 2664,
    "start_time": "2023-01-18T06:42:56.770Z"
   },
   {
    "duration": 31318,
    "start_time": "2023-01-18T06:42:59.436Z"
   },
   {
    "duration": 38,
    "start_time": "2023-01-18T06:43:30.756Z"
   },
   {
    "duration": 180,
    "start_time": "2023-01-18T06:43:30.796Z"
   },
   {
    "duration": 921,
    "start_time": "2023-01-18T06:44:52.457Z"
   },
   {
    "duration": 388,
    "start_time": "2023-01-18T06:45:05.088Z"
   },
   {
    "duration": 12,
    "start_time": "2023-01-18T06:45:20.016Z"
   },
   {
    "duration": 966,
    "start_time": "2023-01-18T06:45:38.352Z"
   },
   {
    "duration": 955,
    "start_time": "2023-01-18T06:45:48.449Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-18T06:45:57.801Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T06:46:21.542Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-18T06:46:53.329Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-18T06:47:00.922Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-18T06:47:41.194Z"
   },
   {
    "duration": 7531,
    "start_time": "2023-01-18T06:48:45.074Z"
   },
   {
    "duration": 652,
    "start_time": "2023-01-18T06:51:11.268Z"
   },
   {
    "duration": 279,
    "start_time": "2023-01-18T07:49:53.956Z"
   },
   {
    "duration": 519,
    "start_time": "2023-01-18T07:53:55.565Z"
   },
   {
    "duration": 53,
    "start_time": "2023-01-18T07:56:05.486Z"
   },
   {
    "duration": 65,
    "start_time": "2023-01-18T07:56:13.222Z"
   },
   {
    "duration": 52,
    "start_time": "2023-01-18T07:56:40.166Z"
   },
   {
    "duration": 59,
    "start_time": "2023-01-18T07:56:46.461Z"
   },
   {
    "duration": 43703,
    "start_time": "2023-01-18T07:57:11.222Z"
   },
   {
    "duration": 258,
    "start_time": "2023-01-18T07:58:09.699Z"
   },
   {
    "duration": 161,
    "start_time": "2023-01-18T07:59:11.800Z"
   },
   {
    "duration": 164,
    "start_time": "2023-01-18T08:00:15.712Z"
   },
   {
    "duration": 57,
    "start_time": "2023-01-18T08:04:41.274Z"
   },
   {
    "duration": 48,
    "start_time": "2023-01-18T08:05:54.307Z"
   },
   {
    "duration": 49,
    "start_time": "2023-01-18T08:06:03.266Z"
   },
   {
    "duration": 12765,
    "start_time": "2023-01-18T08:06:06.706Z"
   },
   {
    "duration": 1342,
    "start_time": "2023-01-18T08:06:39.523Z"
   },
   {
    "duration": 6,
    "start_time": "2023-01-18T08:06:53.267Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-18T08:07:24.203Z"
   },
   {
    "duration": 34,
    "start_time": "2023-01-18T08:07:32.611Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-18T08:07:48.875Z"
   },
   {
    "duration": 21,
    "start_time": "2023-01-18T08:09:52.811Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T08:10:01.492Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T08:10:11.172Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T08:10:34.557Z"
   },
   {
    "duration": 6,
    "start_time": "2023-01-18T08:11:00.837Z"
   },
   {
    "duration": 1327,
    "start_time": "2023-01-18T08:11:09.868Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-18T08:11:11.197Z"
   },
   {
    "duration": 21,
    "start_time": "2023-01-18T08:38:34.520Z"
   },
   {
    "duration": 21,
    "start_time": "2023-01-18T09:40:51.878Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-18T09:41:23.214Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-18T09:42:07.270Z"
   },
   {
    "duration": 1387,
    "start_time": "2023-01-18T09:42:11.014Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-18T09:42:12.404Z"
   },
   {
    "duration": 527,
    "start_time": "2023-01-18T11:30:23.758Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-18T11:30:24.287Z"
   },
   {
    "duration": 13190,
    "start_time": "2023-01-18T11:30:29.987Z"
   },
   {
    "duration": 1818,
    "start_time": "2023-01-18T11:30:43.179Z"
   },
   {
    "duration": 4394,
    "start_time": "2023-01-18T11:30:44.998Z"
   },
   {
    "duration": 30473,
    "start_time": "2023-01-18T11:30:49.393Z"
   },
   {
    "duration": 21,
    "start_time": "2023-01-18T11:31:19.868Z"
   },
   {
    "duration": 180,
    "start_time": "2023-01-18T11:31:19.891Z"
   },
   {
    "duration": 21,
    "start_time": "2023-01-18T11:43:50.241Z"
   },
   {
    "duration": 159,
    "start_time": "2023-01-18T11:43:50.488Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-18T11:43:56.160Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-18T11:44:04.601Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-18T11:44:19.368Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T11:44:31.984Z"
   },
   {
    "duration": 110,
    "start_time": "2023-01-18T11:44:41.696Z"
   },
   {
    "duration": 11,
    "start_time": "2023-01-18T11:44:42.000Z"
   },
   {
    "duration": 2467,
    "start_time": "2023-01-18T11:44:52.073Z"
   },
   {
    "duration": 277,
    "start_time": "2023-01-18T11:44:55.416Z"
   },
   {
    "duration": 11270,
    "start_time": "2023-01-18T11:45:03.008Z"
   },
   {
    "duration": 1672,
    "start_time": "2023-01-18T12:00:33.879Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-18T12:00:36.839Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T12:07:57.905Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T12:08:19.777Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-18T12:08:27.073Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-18T12:10:57.987Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T12:11:04.722Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T12:12:07.267Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T12:12:45.763Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T12:12:57.307Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-18T12:14:15.595Z"
   },
   {
    "duration": 1240,
    "start_time": "2023-01-18T12:14:25.723Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-18T12:14:28.140Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-18T12:14:43.244Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-18T12:15:28.180Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-18T12:15:55.740Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-18T12:16:07.612Z"
   },
   {
    "duration": 8453,
    "start_time": "2023-01-18T12:16:23.715Z"
   },
   {
    "duration": 1253,
    "start_time": "2023-01-18T12:16:36.957Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-18T12:16:38.211Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-18T12:16:43.554Z"
   },
   {
    "duration": 6,
    "start_time": "2023-01-18T12:17:27.444Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-18T12:17:40.533Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T12:17:48.653Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-18T12:17:56.197Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T12:18:13.797Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T12:19:54.590Z"
   },
   {
    "duration": 10,
    "start_time": "2023-01-18T13:37:52.551Z"
   },
   {
    "duration": 27,
    "start_time": "2023-01-18T13:42:48.206Z"
   },
   {
    "duration": 9,
    "start_time": "2023-01-18T13:43:59.877Z"
   },
   {
    "duration": 6,
    "start_time": "2023-01-18T13:46:57.103Z"
   },
   {
    "duration": 69,
    "start_time": "2023-01-18T13:47:43.408Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-18T13:48:04.208Z"
   },
   {
    "duration": 23,
    "start_time": "2023-01-18T13:49:52.072Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-18T13:50:02.001Z"
   },
   {
    "duration": 21,
    "start_time": "2023-01-18T13:51:25.297Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T13:52:57.864Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T13:53:09.921Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T14:09:19.832Z"
   },
   {
    "duration": 30,
    "start_time": "2023-01-18T14:09:33.431Z"
   },
   {
    "duration": 30,
    "start_time": "2023-01-18T14:09:57.919Z"
   },
   {
    "duration": 34,
    "start_time": "2023-01-18T14:10:10.592Z"
   },
   {
    "duration": 30,
    "start_time": "2023-01-18T14:11:02.792Z"
   },
   {
    "duration": 31,
    "start_time": "2023-01-18T14:11:27.762Z"
   },
   {
    "duration": 69,
    "start_time": "2023-01-18T14:13:47.785Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T14:14:01.009Z"
   },
   {
    "duration": 105,
    "start_time": "2023-01-18T14:14:20.001Z"
   },
   {
    "duration": 29,
    "start_time": "2023-01-18T14:15:00.330Z"
   },
   {
    "duration": 17,
    "start_time": "2023-01-18T14:15:19.337Z"
   },
   {
    "duration": 24,
    "start_time": "2023-01-18T14:15:38.650Z"
   },
   {
    "duration": 12,
    "start_time": "2023-01-18T14:19:30.859Z"
   },
   {
    "duration": 89,
    "start_time": "2023-01-18T14:20:38.404Z"
   },
   {
    "duration": 9,
    "start_time": "2023-01-18T14:21:40.524Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-18T14:23:49.501Z"
   },
   {
    "duration": 80,
    "start_time": "2023-01-18T14:34:05.891Z"
   },
   {
    "duration": 21,
    "start_time": "2023-01-18T14:34:29.969Z"
   },
   {
    "duration": 19,
    "start_time": "2023-01-18T14:34:47.465Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-18T14:35:24.514Z"
   },
   {
    "duration": 16,
    "start_time": "2023-01-18T14:35:37.474Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T14:38:14.699Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T14:38:28.699Z"
   },
   {
    "duration": 22,
    "start_time": "2023-01-18T15:22:47.669Z"
   },
   {
    "duration": 20,
    "start_time": "2023-01-18T15:22:59.788Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T15:23:37.477Z"
   },
   {
    "duration": 6,
    "start_time": "2023-01-18T15:23:51.628Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-18T15:24:47.989Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-18T15:26:04.284Z"
   },
   {
    "duration": 9,
    "start_time": "2023-01-18T15:27:03.247Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-18T15:30:58.968Z"
   },
   {
    "duration": 6,
    "start_time": "2023-01-18T15:31:01.199Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T15:31:41.944Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T15:31:54.625Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T15:32:00.831Z"
   },
   {
    "duration": 1382,
    "start_time": "2023-01-18T17:36:54.329Z"
   },
   {
    "duration": 17,
    "start_time": "2023-01-18T17:37:32.593Z"
   },
   {
    "duration": 23,
    "start_time": "2023-01-18T17:37:41.394Z"
   },
   {
    "duration": 18,
    "start_time": "2023-01-18T17:37:44.721Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T17:37:49.177Z"
   },
   {
    "duration": 2,
    "start_time": "2023-01-18T17:38:18.203Z"
   },
   {
    "duration": 1273,
    "start_time": "2023-01-18T17:38:24.218Z"
   },
   {
    "duration": 1220,
    "start_time": "2023-01-18T17:40:17.690Z"
   },
   {
    "duration": 2364,
    "start_time": "2023-01-18T17:40:26.090Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T17:41:17.915Z"
   },
   {
    "duration": 1294,
    "start_time": "2023-01-18T17:41:30.796Z"
   },
   {
    "duration": 6,
    "start_time": "2023-01-18T17:41:43.810Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T17:41:53.075Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T17:42:40.971Z"
   },
   {
    "duration": 20,
    "start_time": "2023-01-18T17:49:44.197Z"
   },
   {
    "duration": 18,
    "start_time": "2023-01-18T17:49:48.726Z"
   },
   {
    "duration": 32,
    "start_time": "2023-01-18T17:50:43.134Z"
   },
   {
    "duration": 29,
    "start_time": "2023-01-18T17:51:01.398Z"
   },
   {
    "duration": 23,
    "start_time": "2023-01-18T17:51:30.510Z"
   },
   {
    "duration": 18,
    "start_time": "2023-01-18T17:51:41.790Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-18T17:52:07.126Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-18T17:54:34.495Z"
   },
   {
    "duration": 42,
    "start_time": "2023-01-18T17:55:41.472Z"
   },
   {
    "duration": 3878,
    "start_time": "2023-01-18T17:56:33.305Z"
   },
   {
    "duration": 106,
    "start_time": "2023-01-18T17:57:19.768Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T17:58:13.202Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-18T18:02:08.931Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T18:02:55.723Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T18:04:18.676Z"
   },
   {
    "duration": 8475,
    "start_time": "2023-01-18T18:05:11.219Z"
   },
   {
    "duration": 1746,
    "start_time": "2023-01-18T18:06:47.149Z"
   },
   {
    "duration": 509,
    "start_time": "2023-01-18T18:07:27.293Z"
   },
   {
    "duration": 1255,
    "start_time": "2023-01-18T18:08:51.773Z"
   },
   {
    "duration": 6,
    "start_time": "2023-01-18T18:08:57.437Z"
   },
   {
    "duration": 68,
    "start_time": "2023-01-18T18:10:21.430Z"
   },
   {
    "duration": 151,
    "start_time": "2023-01-18T18:10:22.669Z"
   },
   {
    "duration": 31,
    "start_time": "2023-01-18T18:11:04.206Z"
   },
   {
    "duration": 6,
    "start_time": "2023-01-18T18:11:27.138Z"
   },
   {
    "duration": 1764,
    "start_time": "2023-01-18T18:11:35.142Z"
   },
   {
    "duration": 584,
    "start_time": "2023-01-18T18:11:39.614Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-18T18:12:47.479Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-18T18:13:59.895Z"
   },
   {
    "duration": 23,
    "start_time": "2023-01-18T18:14:30.120Z"
   },
   {
    "duration": 140,
    "start_time": "2023-01-18T18:14:30.415Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T18:14:50.455Z"
   },
   {
    "duration": 294,
    "start_time": "2023-01-18T18:15:00.800Z"
   },
   {
    "duration": 20230,
    "start_time": "2023-01-18T18:15:20.569Z"
   },
   {
    "duration": 895,
    "start_time": "2023-01-18T18:15:40.801Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T18:15:41.698Z"
   },
   {
    "duration": 10,
    "start_time": "2023-01-18T18:16:07.464Z"
   },
   {
    "duration": 13797,
    "start_time": "2023-01-18T18:16:13.907Z"
   },
   {
    "duration": 1967,
    "start_time": "2023-01-18T18:16:40.329Z"
   },
   {
    "duration": 98,
    "start_time": "2023-01-18T18:16:42.298Z"
   },
   {
    "duration": 11,
    "start_time": "2023-01-18T18:18:28.065Z"
   },
   {
    "duration": 13251,
    "start_time": "2023-01-18T18:18:28.448Z"
   },
   {
    "duration": 1995,
    "start_time": "2023-01-18T18:18:41.701Z"
   },
   {
    "duration": 97,
    "start_time": "2023-01-18T18:18:43.698Z"
   },
   {
    "duration": 168,
    "start_time": "2023-01-18T18:21:51.754Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-18T18:21:54.674Z"
   },
   {
    "duration": 5176,
    "start_time": "2023-01-18T18:22:05.162Z"
   },
   {
    "duration": 2688,
    "start_time": "2023-01-18T18:23:44.619Z"
   },
   {
    "duration": 3188,
    "start_time": "2023-01-18T18:23:47.309Z"
   },
   {
    "duration": 160,
    "start_time": "2023-01-18T18:24:33.052Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T18:24:36.147Z"
   },
   {
    "duration": 227,
    "start_time": "2023-01-18T18:24:40.051Z"
   },
   {
    "duration": 12790,
    "start_time": "2023-01-18T18:24:46.515Z"
   },
   {
    "duration": 294,
    "start_time": "2023-01-18T18:25:08.851Z"
   },
   {
    "duration": 87,
    "start_time": "2023-01-18T18:25:51.380Z"
   },
   {
    "duration": 98,
    "start_time": "2023-01-18T18:28:46.225Z"
   },
   {
    "duration": 1685,
    "start_time": "2023-01-18T18:30:04.525Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-18T18:30:17.349Z"
   },
   {
    "duration": 95973,
    "start_time": "2023-01-18T18:30:26.933Z"
   },
   {
    "duration": 4908,
    "start_time": "2023-01-18T18:32:02.908Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-18T18:32:07.818Z"
   },
   {
    "duration": 47,
    "start_time": "2023-01-18T18:33:43.375Z"
   },
   {
    "duration": 84937,
    "start_time": "2023-01-18T18:33:51.366Z"
   },
   {
    "duration": 10706,
    "start_time": "2023-01-18T18:35:16.395Z"
   },
   {
    "duration": 193,
    "start_time": "2023-01-18T18:35:27.103Z"
   },
   {
    "duration": 68,
    "start_time": "2023-01-18T18:40:43.424Z"
   },
   {
    "duration": 184,
    "start_time": "2023-01-18T18:40:43.648Z"
   },
   {
    "duration": 189,
    "start_time": "2023-01-18T18:41:12.889Z"
   },
   {
    "duration": 174,
    "start_time": "2023-01-18T18:41:19.737Z"
   },
   {
    "duration": 173,
    "start_time": "2023-01-18T18:42:09.545Z"
   },
   {
    "duration": 193,
    "start_time": "2023-01-18T18:42:16.481Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-18T18:42:59.505Z"
   },
   {
    "duration": 1178,
    "start_time": "2023-01-18T18:43:11.538Z"
   },
   {
    "duration": 59021,
    "start_time": "2023-01-18T18:43:13.865Z"
   },
   {
    "duration": 3161,
    "start_time": "2023-01-18T18:44:12.889Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T18:44:16.051Z"
   },
   {
    "duration": 33,
    "start_time": "2023-01-18T18:44:23.075Z"
   },
   {
    "duration": 46775,
    "start_time": "2023-01-18T18:44:28.418Z"
   },
   {
    "duration": 3099,
    "start_time": "2023-01-18T18:45:15.196Z"
   },
   {
    "duration": 196,
    "start_time": "2023-01-18T18:45:18.298Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-18T18:48:39.652Z"
   },
   {
    "duration": 107,
    "start_time": "2023-01-18T18:48:40.556Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-18T18:49:12.172Z"
   },
   {
    "duration": 375,
    "start_time": "2023-01-18T18:49:12.388Z"
   },
   {
    "duration": 18193,
    "start_time": "2023-01-18T18:49:16.115Z"
   },
   {
    "duration": 955,
    "start_time": "2023-01-18T18:49:34.310Z"
   },
   {
    "duration": 80,
    "start_time": "2023-01-18T18:50:33.517Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-18T18:50:57.181Z"
   },
   {
    "duration": 341,
    "start_time": "2023-01-18T18:50:57.604Z"
   },
   {
    "duration": 2786,
    "start_time": "2023-01-18T18:53:04.206Z"
   },
   {
    "duration": 3309,
    "start_time": "2023-01-18T18:53:06.994Z"
   },
   {
    "duration": 46,
    "start_time": "2023-01-18T18:53:21.934Z"
   },
   {
    "duration": 196,
    "start_time": "2023-01-18T18:53:22.214Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-18T18:53:27.469Z"
   },
   {
    "duration": 2423,
    "start_time": "2023-01-18T18:53:35.357Z"
   },
   {
    "duration": 942,
    "start_time": "2023-01-18T18:53:42.715Z"
   },
   {
    "duration": 59840,
    "start_time": "2023-01-18T18:53:44.805Z"
   },
   {
    "duration": 2861,
    "start_time": "2023-01-18T18:54:44.647Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-18T18:54:47.509Z"
   },
   {
    "duration": 33,
    "start_time": "2023-01-18T18:55:08.801Z"
   },
   {
    "duration": 50660,
    "start_time": "2023-01-18T18:55:09.342Z"
   },
   {
    "duration": 3293,
    "start_time": "2023-01-18T18:56:00.007Z"
   },
   {
    "duration": 101,
    "start_time": "2023-01-18T18:56:03.302Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-18T18:56:11.480Z"
   },
   {
    "duration": 396,
    "start_time": "2023-01-18T18:56:12.257Z"
   },
   {
    "duration": 51,
    "start_time": "2023-01-18T18:56:17.726Z"
   },
   {
    "duration": 19112,
    "start_time": "2023-01-18T18:56:38.151Z"
   },
   {
    "duration": 1021,
    "start_time": "2023-01-18T18:56:57.266Z"
   },
   {
    "duration": 18,
    "start_time": "2023-01-18T18:56:58.294Z"
   },
   {
    "duration": 24,
    "start_time": "2023-01-18T18:57:49.727Z"
   },
   {
    "duration": 168,
    "start_time": "2023-01-18T18:57:51.013Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-18T18:57:54.200Z"
   },
   {
    "duration": 273,
    "start_time": "2023-01-18T18:58:05.472Z"
   },
   {
    "duration": 28307,
    "start_time": "2023-01-18T18:58:13.273Z"
   },
   {
    "duration": 714,
    "start_time": "2023-01-18T18:58:47.905Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T18:58:48.620Z"
   },
   {
    "duration": 10,
    "start_time": "2023-01-18T18:58:58.664Z"
   },
   {
    "duration": 10589,
    "start_time": "2023-01-18T18:58:59.112Z"
   },
   {
    "duration": 1792,
    "start_time": "2023-01-18T18:59:09.703Z"
   },
   {
    "duration": 102,
    "start_time": "2023-01-18T18:59:11.497Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T18:59:14.464Z"
   },
   {
    "duration": 45,
    "start_time": "2023-01-18T18:59:15.113Z"
   },
   {
    "duration": 3927,
    "start_time": "2023-01-18T18:59:18.688Z"
   },
   {
    "duration": 135,
    "start_time": "2023-01-18T18:59:22.618Z"
   },
   {
    "duration": 41,
    "start_time": "2023-01-18T18:59:22.755Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T19:00:35.345Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-18T19:00:45.041Z"
   },
   {
    "duration": 355,
    "start_time": "2023-01-18T19:00:55.345Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-18T19:01:03.915Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T19:01:09.777Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T19:01:15.305Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T19:01:22.719Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T19:01:28.900Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T19:01:34.865Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-18T19:01:40.474Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T19:01:51.618Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T19:01:55.295Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T19:01:58.809Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T19:02:02.711Z"
   },
   {
    "duration": 10,
    "start_time": "2023-01-18T19:04:05.203Z"
   },
   {
    "duration": 29,
    "start_time": "2023-01-18T19:04:34.996Z"
   },
   {
    "duration": 34,
    "start_time": "2023-01-18T19:05:03.601Z"
   },
   {
    "duration": 13596,
    "start_time": "2023-01-18T19:05:16.699Z"
   },
   {
    "duration": 39,
    "start_time": "2023-01-18T19:05:51.620Z"
   },
   {
    "duration": 1190,
    "start_time": "2023-01-18T19:06:02.212Z"
   },
   {
    "duration": 9,
    "start_time": "2023-01-18T19:06:04.099Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T19:07:04.620Z"
   },
   {
    "duration": 11,
    "start_time": "2023-01-18T19:07:06.181Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-18T19:07:14.365Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-18T19:07:24.164Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-18T19:07:30.363Z"
   },
   {
    "duration": 7,
    "start_time": "2023-01-18T19:07:43.660Z"
   },
   {
    "duration": 13,
    "start_time": "2023-01-18T19:07:44.892Z"
   },
   {
    "duration": 8,
    "start_time": "2023-01-18T19:08:06.677Z"
   },
   {
    "duration": 12293,
    "start_time": "2023-01-18T19:08:09.500Z"
   },
   {
    "duration": 1603,
    "start_time": "2023-01-18T19:08:21.796Z"
   },
   {
    "duration": 100,
    "start_time": "2023-01-18T19:08:23.402Z"
   },
   {
    "duration": 3489,
    "start_time": "2023-01-18T19:08:37.748Z"
   },
   {
    "duration": 119,
    "start_time": "2023-01-18T19:08:41.239Z"
   },
   {
    "duration": 133,
    "start_time": "2023-01-18T19:08:41.360Z"
   },
   {
    "duration": 448,
    "start_time": "2023-01-19T04:55:31.671Z"
   },
   {
    "duration": 12949,
    "start_time": "2023-01-19T04:55:34.622Z"
   },
   {
    "duration": 1598,
    "start_time": "2023-01-19T04:55:47.574Z"
   },
   {
    "duration": 2277,
    "start_time": "2023-01-19T04:55:49.174Z"
   },
   {
    "duration": 276,
    "start_time": "2023-01-19T04:56:33.568Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-19T04:56:50.726Z"
   },
   {
    "duration": 2407,
    "start_time": "2023-01-19T04:56:51.060Z"
   },
   {
    "duration": 382,
    "start_time": "2023-01-19T04:56:53.469Z"
   },
   {
    "duration": 387,
    "start_time": "2023-01-19T04:56:57.599Z"
   },
   {
    "duration": 64,
    "start_time": "2023-01-19T04:56:58.126Z"
   },
   {
    "duration": 14448,
    "start_time": "2023-01-19T04:57:07.367Z"
   },
   {
    "duration": 38537,
    "start_time": "2023-01-19T04:57:25.265Z"
   },
   {
    "duration": 997,
    "start_time": "2023-01-19T04:58:03.805Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-19T04:58:04.804Z"
   },
   {
    "duration": 19,
    "start_time": "2023-01-19T04:58:04.811Z"
   },
   {
    "duration": 11342,
    "start_time": "2023-01-19T04:58:04.832Z"
   },
   {
    "duration": 2396,
    "start_time": "2023-01-19T04:58:16.176Z"
   },
   {
    "duration": 195,
    "start_time": "2023-01-19T04:58:18.575Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-19T04:59:06.128Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-19T05:00:05.801Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-19T05:00:13.976Z"
   },
   {
    "duration": 119,
    "start_time": "2023-01-19T05:03:04.314Z"
   },
   {
    "duration": 1785,
    "start_time": "2023-01-19T05:03:23.864Z"
   },
   {
    "duration": 70,
    "start_time": "2023-01-19T05:05:30.707Z"
   },
   {
    "duration": 118,
    "start_time": "2023-01-19T05:05:35.531Z"
   },
   {
    "duration": 4313286,
    "start_time": "2023-01-19T05:06:49.063Z"
   },
   {
    "duration": 9,
    "start_time": "2023-01-19T06:21:55.830Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-23T08:18:25.217Z"
   },
   {
    "duration": 19,
    "start_time": "2023-01-23T08:18:25.223Z"
   },
   {
    "duration": 8099,
    "start_time": "2023-01-23T08:18:25.244Z"
   },
   {
    "duration": 2202,
    "start_time": "2023-01-23T08:18:33.345Z"
   },
   {
    "duration": 374,
    "start_time": "2023-01-23T08:18:35.549Z"
   },
   {
    "duration": 92,
    "start_time": "2023-01-23T08:18:35.925Z"
   },
   {
    "duration": 700,
    "start_time": "2023-01-23T08:18:36.019Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-23T08:18:36.721Z"
   },
   {
    "duration": 0,
    "start_time": "2023-01-23T08:18:36.723Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-23T08:19:27.508Z"
   },
   {
    "duration": 5,
    "start_time": "2023-01-23T08:19:27.515Z"
   },
   {
    "duration": 5223,
    "start_time": "2023-01-23T08:19:27.522Z"
   },
   {
    "duration": 2142,
    "start_time": "2023-01-23T08:19:32.747Z"
   },
   {
    "duration": 394,
    "start_time": "2023-01-23T08:19:34.891Z"
   },
   {
    "duration": 84,
    "start_time": "2023-01-23T08:19:35.292Z"
   },
   {
    "duration": 45,
    "start_time": "2023-01-23T08:19:35.378Z"
   },
   {
    "duration": 22,
    "start_time": "2023-01-23T08:19:35.425Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-23T08:20:07.560Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
